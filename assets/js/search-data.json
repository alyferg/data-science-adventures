{
  
    
        "post0": {
            "title": "Resources",
            "content": "It is important to have the right resources to hand to make the whole job lot easier. Perhaps the most important of these for the novice are the training resources and information but there are also a raft of other sites blogs and tools that can can make the whole process more straightforward. . The initial choice when researching information or learning about Machine Learning is either utilising blogs or YouTube. Personally, I prefer to use YouTube as I find that a lot easier to follow and can also see the code and the results on the screen. Thats not to say that I don&#39;t use blogs that can provide a useful depth that perhaps YouTube doesn&#39;t and quite often the blogs such as my own include blocks of code that you can copy to try out for yourself. . The volume of videos on YouTube is incredible and many of them are really long. There a some the contain a full 12-hour course and 3 to 4-hour videos are not uncommon. The beauty of many of these videos is that they are properly indexed with chapter markings though some of the older ones don&#39;t. Many of the video descriptions also provide links to the code either on github or a website that can be downloaded to follow along. It is truly amazing the volume and quality of the content available on YouTube on the subject of Machine Learning and a testament to the community that are prepared to put so much time and effort in to disseminating their knowledge. . Here are some of the useful channels that I have discovered on YouTube. This is not intended as an exhaustive list or a recommendation or I can say is that I have found these particular channels very useful in in gaining the understanding I now have of the subject. There are many many more. . Simplilearn Siraj Raval 3blue1brown edeureka Tech with Tim . But this is perhaps the most comprehensive one I found about deep learning it is a full course and very worthy of your attention if you are serious about learning more. . Practical Deep Learning for Coders . In the same vain here are a number of of blogs/websites that I am found useful easy for following particular subjects or or looking up one particular Key area. . stackoverflow a great source of wisdom and answers on many subjects. freecodecamp.org some great articles, I particularly like the flow of many of them. Python Data Science Handbook comprehensive and structured list of Python Data Science topics. pythonguides plenty of help in Python with examples. kite another very detailed list of useful code and topics. . There are many many more available, I am sure you can find your own. . I am sure that there are many different tools out there that people will find particularly useful depending on their exact requirements. Here are 2 that I have found particularly useful. . Grepper . Githib . Finally, for comprehensive access to many publicly available datasets to play, test and learn from then look at Kaggle. They also run competitions from time to time to help hone your skills. . Kaggle . For the Data Science example in this blog I have chosen the &quot;modeschoice&quot; dataset. The statsmodels explanation of this dataset is; . The data, collected as part of a 1987 intercity mode choice study, are a sub-sample of 210 non-business trips between Sydney, Canberra and Melbourne in which the traveler chooses a mode from four alternatives (plane, car, bus and train). . In this example we will be looking at &quot;Terminal Time&quot; i.e. the time waiting at the terminal for the chosen mode of transport. As the assumption of the survey is that when using a car there is zero waiting time. Therefore, we will be charting the average wait time of Air, Rail and Bus Transport. . import pandas as pd import numpy as np import statsmodels.api as sm from matplotlib import pyplot as plt modechoice = sm.datasets.modechoice df = modechoice.load_pandas().data #check that the data is loaded and see how it looks df . individual mode choice ttme invc invt gc hinc psize . 0 1.0 | 1.0 | 0.0 | 69.0 | 59.0 | 100.0 | 70.0 | 35.0 | 1.0 | . 1 1.0 | 2.0 | 0.0 | 34.0 | 31.0 | 372.0 | 71.0 | 35.0 | 1.0 | . 2 1.0 | 3.0 | 0.0 | 35.0 | 25.0 | 417.0 | 70.0 | 35.0 | 1.0 | . 3 1.0 | 4.0 | 1.0 | 0.0 | 10.0 | 180.0 | 30.0 | 35.0 | 1.0 | . 4 2.0 | 1.0 | 0.0 | 64.0 | 58.0 | 68.0 | 68.0 | 30.0 | 2.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 835 209.0 | 4.0 | 1.0 | 0.0 | 27.0 | 510.0 | 82.0 | 20.0 | 1.0 | . 836 210.0 | 1.0 | 0.0 | 64.0 | 66.0 | 140.0 | 87.0 | 70.0 | 4.0 | . 837 210.0 | 2.0 | 0.0 | 44.0 | 54.0 | 670.0 | 156.0 | 70.0 | 4.0 | . 838 210.0 | 3.0 | 0.0 | 53.0 | 33.0 | 664.0 | 134.0 | 70.0 | 4.0 | . 839 210.0 | 4.0 | 1.0 | 0.0 | 12.0 | 540.0 | 94.0 | 70.0 | 4.0 | . 840 rows × 9 columns . #this gives us the average wait time for each mode air = df.groupby(&#39;mode&#39;)[&#39;ttme&#39;].mean() #view the table air . mode 1.0 61.009524 2.0 35.690476 3.0 41.657143 4.0 0.000000 Name: ttme, dtype: float64 . labels = [&#39;Plane - 61&#39;,&#39;Train - 35&#39;,&#39;Bus - 41&#39;, &#39;Car - 0&#39;] # plot the pie chart plot = air.plot.pie(labeldistance=None, autopct=&#39;%1.1f%%&#39;,figsize=(10, 10)) plt.legend(loc=&#39;best&#39;,title=&#39;Average wait time (mins)&#39;,title_fontsize=&#39;large&#39;,labels=labels) . &lt;matplotlib.legend.Legend at 0x7fd4b50e6940&gt; . Therefore, if you took an equal number of trips via Air, Rail and Bus then you would spend 44.1% of your waiting time waiting at the Airport, 25.8% at the Rail Station and 30.1% at the Bus Station. . The legend shows the average wait time for each. .",
            "url": "https://alyferg.github.io/data-science-adventures/2021/10/28/Resources.html",
            "relUrl": "/2021/10/28/Resources.html",
            "date": " • Oct 28, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Environment",
            "content": "Having the correct environment for running your Python code is very important. I have found that having two environments to run code can be beneficial. The first of these is a machine resident version and the second is online with an IDE. . My normal machine is a Chromebook running a Linux container which is ideal for the majority of software around today. For Python I have created an Anaconda environment within the Linux container which enables me to run either Jupyter notebooks or Spyder as a Python development environment. I did start by running Spyder probably because I&#39;m still a little bit old school and like to see things and know where they are. Spyder gives you the option to to interrogate variables and tables which can be useful. However, I have now started using Jupyter notebooks almost exclusively because the flexibility enables you to work in a more structured way and also make plenty of notes as you go along.&quot; . When I say that I am little bit old school in some things that is very true. I did start programming originally in Basic if anyone remembers this, in fact at one time I was uploading Hex instructions into microprocessors to make them do things. Moving on from Basic then I did some programming in Pascal, Cobol and several other languages. The more modern languages have generally escaped me with the exception of a brief detour into Java several years ago. This was mainly due to my work arrangements rather than a lack of interest in pursuing a programming career. . Anyway, back to environment. The Linux environment is ideal for me as I do travel from time to time and so don&#39;t always have access to online facilities. It is perfect for running smaller machine learning operations such as regression or decision trees. It also gives you control over the environment and is available whenever needed. . If you do intend to undertake any form of Deep Learning though, then you will probably need an online IDE. I say this because the power required to undertake Deep Learning tasks will require access to GPU computing power. That is unless you are lucky enough to have the hardware at home, My choice of IDE is Gradient which is free and powerful but can be hard to connect at busy times. Gradient can be found here . So, armed with your environments whether single or double, local or remote, then you are good to go. . This time we will do some analysis on another well-known dataset, the Boston Housing Dataset. . import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns %matplotlib inline from sklearn.datasets import load_boston boston = load_boston() df = pd.DataFrame(boston.data).head() # drop a column of zero entries df.drop(3,1, inplace = True) #lets also have a look at the data df.head() . /tmp/ipykernel_10189/410762870.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument &#39;labels&#39; will be keyword-only df.drop(3,1, inplace = True) . 0 1 2 4 5 6 7 8 9 10 11 12 . 0 0.00632 | 18.0 | 2.31 | 0.538 | 6.575 | 65.2 | 4.0900 | 1.0 | 296.0 | 15.3 | 396.90 | 4.98 | . 1 0.02731 | 0.0 | 7.07 | 0.469 | 6.421 | 78.9 | 4.9671 | 2.0 | 242.0 | 17.8 | 396.90 | 9.14 | . 2 0.02729 | 0.0 | 7.07 | 0.469 | 7.185 | 61.1 | 4.9671 | 2.0 | 242.0 | 17.8 | 392.83 | 4.03 | . 3 0.03237 | 0.0 | 2.18 | 0.458 | 6.998 | 45.8 | 6.0622 | 3.0 | 222.0 | 18.7 | 394.63 | 2.94 | . 4 0.06905 | 0.0 | 2.18 | 0.458 | 7.147 | 54.2 | 6.0622 | 3.0 | 222.0 | 18.7 | 396.90 | 5.33 | . correlation = df.corr().round(3) plt.figure(figsize = (15,10)) sns.heatmap(data=correlation, annot=True) . &lt;AxesSubplot:&gt; . A heatmap such as this is often the first step in looking for correlation between columns in a dataset. The level of correlation is shown by the figure in each square with 1 being 100% and 0 being 0%. The colours give a useful quick visual guide. The lighter the better and the darker the less or negative correlation. . Of course, this leads me to one final and very important point. One thing that has become very evident quickly is the importance of looking at the data and just as important visualising it in some way. Whether this be with graphs, scatter diagrams or heatmaps it&#39;s vital to have an understanding of how the data looks and visualisations of this type are a good way to do it. .",
            "url": "https://alyferg.github.io/data-science-adventures/2021/10/26/Environment.html",
            "relUrl": "/2021/10/26/Environment.html",
            "date": " • Oct 26, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Begining",
            "content": "1 month ago I only knew that Python did actually exist but had never written a line of code for it. Similarly, whilst the prospect of understanding Data Science was something that I would find interesting, the idea of actually doing anything with it seemed remote. Then I discovered an application I wanted to follow through for which Data Science seemed to be the ideal solution. And so began a journey that even in a short space of time has taken me so far. . There are a number of things that I have learnt very quickly. . that the internet is awash with resources to support anyone wishing to learn about python and Data Science. So much so, that sometimes it&#39;s difficult to know when to leave off and start being practical. | I have been truly amazed at the number and quality of data sets that are freely available out there to be used either for real-world calculations or for testing to develop systems. | that it really is not as difficult as you may think and even within a short space of time you can be producing meaningful results from the data we all have access to. | So, as much as a journal for me rather than being a mechanism for passing on any wisdom a Blog seemed to be the ideal way to go. This blog is built using Jupyter notebooks that are turned into blog posts automatically by Fastpages via github. More about that later. . I don&#39;t think any blog on the subject of Data Science especially one written in a Jupyter notebook would be complete without some kind of code and graphical representation. . There are numerous datasets available on websites and indeed within Python modules and libraries. Soem are very well-know such as this one. The Iris dataset. We will load it and plot a scatter diagram of the columns to see if there is any correlation between them. . #here we will load the famous Iris dataset after loading modules import matplotlib.pyplot as plt import pandas as pd import numpy as np from sklearn import datasets from pandas.plotting import scatter_matrix #load the iris dataset iris = datasets.load_iris() df = pd.DataFrame(iris.data, columns=iris.feature_names) #lets have a quick check on the data df.head() . sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) . 0 5.1 | 3.5 | 1.4 | 0.2 | . 1 4.9 | 3.0 | 1.4 | 0.2 | . 2 4.7 | 3.2 | 1.3 | 0.2 | . 3 4.6 | 3.1 | 1.5 | 0.2 | . 4 5.0 | 3.6 | 1.4 | 0.2 | . #this will plot a scatter plot of each column against every other to look for correlation scatter_matrix(df, figsize=(10,10)) . array([[&lt;AxesSubplot:xlabel=&#39;sepal length (cm)&#39;, ylabel=&#39;sepal length (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;sepal width (cm)&#39;, ylabel=&#39;sepal length (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;petal length (cm)&#39;, ylabel=&#39;sepal length (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;petal width (cm)&#39;, ylabel=&#39;sepal length (cm)&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;sepal length (cm)&#39;, ylabel=&#39;sepal width (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;sepal width (cm)&#39;, ylabel=&#39;sepal width (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;petal length (cm)&#39;, ylabel=&#39;sepal width (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;petal width (cm)&#39;, ylabel=&#39;sepal width (cm)&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;sepal length (cm)&#39;, ylabel=&#39;petal length (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;sepal width (cm)&#39;, ylabel=&#39;petal length (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;petal length (cm)&#39;, ylabel=&#39;petal length (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;petal width (cm)&#39;, ylabel=&#39;petal length (cm)&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;sepal length (cm)&#39;, ylabel=&#39;petal width (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;sepal width (cm)&#39;, ylabel=&#39;petal width (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;petal length (cm)&#39;, ylabel=&#39;petal width (cm)&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;petal width (cm)&#39;, ylabel=&#39;petal width (cm)&#39;&gt;]], dtype=object) . You can draw your own conclusions from the data. The scatter matrix shows the relationship between the columns of the data. Once you have seen this then you may wish to view another data representation or look for a more detailed view of any specific correlation you see. . So, a very simple start but I&#39;ve learnt a lot more in the last month. This is where I started out and I must admit I&#39;m beginning to enjoy the journey immensely. At the moment I really still don&#39;t know what I don&#39;t know, but I&#39;m enjoying finding out what I don&#39;t know and then filling the gaps. .",
            "url": "https://alyferg.github.io/data-science-adventures/2021/10/25/The_Beginning.html",
            "relUrl": "/2021/10/25/The_Beginning.html",
            "date": " • Oct 25, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://alyferg.github.io/data-science-adventures/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://alyferg.github.io/data-science-adventures/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://alyferg.github.io/data-science-adventures/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://alyferg.github.io/data-science-adventures/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}